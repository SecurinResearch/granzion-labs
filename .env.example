# PostgreSQL Configuration
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=granzion_lab
POSTGRES_USER=granzion
POSTGRES_PASSWORD=changeme_in_production

# Keycloak Configuration
KEYCLOAK_HOST=keycloak
KEYCLOAK_PORT=8080
KEYCLOAK_REALM=granzion-lab
KEYCLOAK_ADMIN=admin
KEYCLOAK_ADMIN_PASSWORD=admin_changeme
KEYCLOAK_CLIENT_ID=granzion-lab-client
KEYCLOAK_CLIENT_SECRET=changeme_client_secret

# LiteLLM Configuration
# Option 1: Use external cloud-hosted LiteLLM proxy (RECOMMENDED)
# Set LITELLM_URL to your company's LiteLLM proxy base URL
LITELLM_URL=https://your-company-litellm-proxy.example.com
LITELLM_API_KEY=your_litellm_api_key_here

# Default model to use for all agents
# For cloud LiteLLM proxies with specific routing, use the full model path
# Example: openai/azure/gpt-4, anthropic/claude-3-opus, etc.
DEFAULT_MODEL=openai/azure/gpt-4

# Option 2: Use local LiteLLM container (for development/testing)
# Uncomment these lines and comment out LITELLM_URL above
# LITELLM_URL=http://litellm:4000
# LITELLM_API_KEY=sk-1234567890abcdef
# DEFAULT_MODEL=gpt-4
# OPENAI_API_KEY=your_openai_key_here
# ANTHROPIC_API_KEY=your_anthropic_key_here
# Then start with: docker compose --profile local-litellm up

# PuppyGraph Configuration
PUPPYGRAPH_HOST=puppygraph
PUPPYGRAPH_PORT=8182       # Gremlin endpoint for graph queries
PUPPYGRAPH_WEB_PORT=8081   # Web UI dashboard

# Application Configuration
APP_ENV=development
LOG_LEVEL=INFO             # DEBUG, INFO, WARNING, ERROR
DEBUG=true

# Red Team Interface
TUI_PORT=8000              # Port for the TUI frontend
API_PORT=8001              # Port for the FastAPI backend

